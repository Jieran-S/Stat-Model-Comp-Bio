tinytex::install_tinytex()
install.packages(formatR)
install.packages(formatR)
formatR
install.packages("formatR")
pwd
library(Seurat)
installed.packages("Seurat")
library(Seurat)
installed.packages("Seurat")
install.packages("Seurat")
library(Seurat)
install.packages('lmtest')
library(Seurat)
install.packages('Seurat')
library(Seurat)
library(lmtest)
install.package('lmtest')
install.packages('lmtest')
remove.packages('lmtest')
remove.packages('Seurat')
remove.packages('Seurat',Seurat)
remove.packages('Seurat','Seurat')
remove.packages(Seurat')
remove.packages('Seurat')
dpkg --list
detach("package:Seurat", unload=TRUE)
detach("Seurat", unload=TRUE)
?detach
detach("lmtest", unload=TRUE)
detach(lmtest, unload=TRUE)
library(SeuratObject)
detach("package:SeuratObject", unload = TRUE)
remove.packages("SeuratObject")
install.packages("Seurat")
install.packages("Seurat")
install.packages("lmtest")
install.packages("Seurat")
library(Seurat)
library(Seurat)
counts <- Read10X(data.dir = "data/DS1/")
seurat <- CreateSeuratObject(counts, project = "D1Trail")
counts <- Read10X(data.dir = "data/DS1/")
seurat <- CreateSeuratObject(counts, project = "D1Trail")
counts <- Read10X(data.dir = "data/DS1/")
seurat <- CreateSeuratObject(counts, project = "D1Trail")
getwd()
g <- function(x) median(x)
m <- c(1,2,3,4,5,6)
g(m)
url <- "https://ww2.amstat.org/publications/jse/datasets/fruitfly.dat.txt"
fly.data <- read.table(url)
fly.data <- fly.data[, - c(1,6)]
names(fly.data) <- c("partners","type","longevity","thorax")
pairs(fly.data)
#What is pairs plot?
#What can you comment on based on this graph?
#logic: fitting the model -> Getting beta hat -> Getting sigma_hat -> Using t-test statistics (beta_hat/XTX sigma_hat) compile to t-test with dof n-p
reg.wtho <- lm(fly.onefemale$longevity ~ factor(fly.onefemale$type) + fly.onefemale$thorax)
fly.onefemale <- subset(fly.data, partners == 1)
#logic: fitting the model -> Getting beta hat -> Getting sigma_hat -> Using t-test statistics (beta_hat/XTX sigma_hat) compile to t-test with dof n-p
reg.wtho <- lm(fly.onefemale$longevity ~ factor(fly.onefemale$type) + fly.onefemale$thorax)
reg.wtho <- lm(longevity ~ factor(type) + thorax, data = fly.onefemale)
reg.wtho <- lm(longevity ~ factor(type) + I(thorax^2), data = fly.onefemale)
typeof(predict(reg.wtho, fly.onefemale))
head(predict(reg.wtho, fly.onefemale))
library(BiocManager)
sessionInfo()
library("limma")
library("ggplot2")
library(matrixStats)
library(cowplot)
library(ROCR)
library(magrittr)
library(dplyr)
library("affy")
library(affy)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("affy")
library(affy)
R
sessionInfo()
library(iSEE)
source("https://bioconductor.org/biocLite.R")
biocLite("RnBeads")
BiocManager::install('RnBeads')
wes_palette("Darjeeling1")
library(wesanderson)
library(wesanderson)
wes_palette("Darjeeling1")
print(wes_palette("Darjeeling1"))
list(wes_palette("Darjeeling1"))
m <- list(wes_palette("Darjeeling1"))
m
m <- c(wes_palette("Darjeeling1"))
m
(c(wes_palette("Darjeeling1")))
(c(wes_palette("Darjeeling2")))
wes_palette("Darjeeling2")
wes_palette("Darjeeling1")
wes_palette("Darjeeling2")
c(wes_palette("FantasticFox1"))
wes_palette("Darjeeling1")
c(wes_palette("Cavalcanti1")
)
c(wes_palette("GrandBudapest2"))
gc()
gc()
suppressPackageStartupMessages({
# data manipulation
library(hdf5r)
library(Seurat)
library(readxl)
library(scDblFinder)
library(data.table)
# pipelining
library(tidyverse)
library(dplyr)
#Processing
library(harmony)
# For plotting
library(ggplot2)
library(RColorBrewer)
library(ggsci)
library(wesanderson)
library(patchwork)
library(gridExtra)
})
data_path <- "/Users/jiesun/Storage/Work/Projects/Microglial_annotation/Data/"
working_path <- "/Users/jiesun/Storage/Work/Projects/Microglial_annotation/Microglial-annotation"
setwd(working_path)
# three different samples: 100-WT, 101 - GpnmbKO, 102-GpnmbKO)
seurat_list <- lapply(list.files( data_path, pattern = "*.h5", full.name =TRUE),
function(file){
file_ind <- which(list.files( data_path, pattern = "*.h5", full.name =TRUE) == file)
seurat_object <- Read10X_h5(file , use.names = TRUE, unique.features = TRUE) %>%
CreateSeuratObject(project = c("WT", "GpnmbKO_1", "GpnmbKO_2")[file_ind], min.cells = 3, min.features = 200)
seurat_object$stim <- sprintf("cond%s", file_ind-1)
seurat_object[["percent.mt"]] <- PercentageFeatureSet(seurat_object, pattern = "^mt-")
seurat_object[["percent.rb"]] <- PercentageFeatureSet(seurat_object, pattern = "^Rp[sl]")
seurat_object
})
# Should also remove the doublet cells
seurat_list <- lapply(seurat_list, function(x) rownames(x)) %>%
{Reduce(intersect, .)} %>%
{lapply(seurat_list, function(x) x[.,])}
seurat_combi <- merge(seurat_list[[1]], seurat_list[-1], project = "CombinedSeurat")
VlnPlot(seurat_combi, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
group.by = "orig.ident", cols = pal_npg("nrc")(3),
ncol = 3, pt.size = 0) + xlab("conditions")
seurat_combi <- seurat_combi %>%
NormalizeData() %>%
FindVariableFeatures(nfeatures = 3000) %>%
ScaleData() %>%
RunPCA(npcs = 50)
# Select essential PCs for clustering
pct <- seurat_combi[["pca"]]@stdev / sum(seurat_combi[["pca"]]@stdev) * 100
choice1 <- which(cumsum(pct) > 80 & pct < 5)[1]
choice2 <- sort(which((pct[1:length(pct) - 1] - pct[2:length(pct)]) > 0.1 & cumsum(pct) > 60 ), decreasing = T)[1] + 1
pcs <- min(choice1, choice2, 40)
ElbowPlot(seurat_combi, ndims= 50) + ylab("variance explained (%)") +
geom_point(x = pcs, y = seurat_combi[["pca"]]@stdev[pcs] , colour = "red") +
geom_label(
label=sprintf("PC selected: %1.0f",pcs),
x=pcs,
y=seurat_combi[["pca"]]@stdev[pcs] + 1,
label.padding = unit(0.55, "lines"), # Rectangle size around label
label.size = 0.35,
color = "black",
fill="#69b3a2")
seurat_combi <- seurat_combi %>% RunHarmony(group.by.vars = "orig.ident", dims.use = 1:pcs, max.iter.harmony = 50) %>%
FindNeighbors(reduction = "harmony", dims = 1:pcs) %>% FindClusters(resolution = 0.5)
seurat_combi <- RunUMAP(seurat_combi, reduction = "harmony", dims = 1:pcs)
Plot1 <- DimPlot(seurat_combi, group.by = "seurat_clusters", label = FALSE, label.color = "black", pt.size = 0.3, cols = pal_simpsons()(16))  + plot_annotation(title="Clusters") + NoAxes()
Plot2 <- DimPlot(seurat_combi, group.by = "orig.ident",pt.size = 0.3, cols = pal_simpsons()(3)) +
plot_annotation(title="Conditions") + NoAxes()
Plot1 + Plot2
# Plot abundance of cells in different conditions
ca <- table(cluster=seurat_combi$seurat_clusters, sample=seurat_combi$orig.ident)
ggplot(as.data.frame(ca), aes(sample, cluster, fill=Freq)) +
geom_tile() + scale_fill_gradientn(colors = wes_palette("IsleofDogs2", 10, type = "continuous")) +
geom_text(aes(label=Freq), color = "white") + coord_fixed(ratio = 0.25) +
guides(fill = guide_colourbar(barwidth = 0.5,barheight = 18))
# Bar plot about the percentage in each cluster given the condition
# Import list of marker genes
marker_list <- read_excel(file.path(working_path,"Marker_list_BU.xlsx")) %>% {.[c(4:13)]}
meta_data <- unlist(tstrsplit(marker_list$Meta_data, ":", fixed = T, keep = 2))
names(meta_data) <- unlist(tstrsplit(marker_list$Meta_data, ":", fixed = T, keep = 1))
meta_data <- meta_data[!is.na(meta_data)]
# Filter and leave only those marker genes in the clusters
exist_list <- lapply(marker_list, function(x){
x <- x[!is.na(x)]
x <- unique(grep(paste(x,collapse="|"), row.names(seurat_combi), ignore.case = TRUE, value=TRUE))
x <- row.names(seurat_combi)[grep(paste(x,collapse="|"), row.names(seurat_combi), ignore.case = TRUE)]})
# Overview of the feature genes distribution in the cell population
DoHeatmap(seurat_combi, features = unique(unlist(exist_list)), group.colors = pal_simpsons()(16))
rm(seurat_list)
# Overview of the feature genes distribution in the cell population
DoHeatmap(seurat_combi, features = unique(unlist(exist_list)), group.colors = pal_simpsons()(16))
library(usethis)
usethis::edit_r_environ()
install.packages("usethis")
library(usethis)
usethis::edit_r_environ()
Sys.setenv('R_MAX_VSIZE'=32000000000)
# Overview of the feature genes distribution in the cell population
DoHeatmap(seurat_combi, features = unique(unlist(exist_list)), group.colors = pal_simpsons()(16))
suppressPackageStartupMessages({
library(data.table)
library(pheatmap)
library(viridis)
})
set.seed(2023)
# read the data into D
D <- read.csv("coinflip.csv")
# check the dimension of D
all(dim(D) == c(200, 100))
# Number of coins
k <- 2
# Mixture weights (a vector of length k)
lambda <- c(0.5, 0.5)
# Probabilities of obtaining heads (a vector of length k)
theta <- runif(2)
##' This function implements the EM algorithm for the coin toss problem
##' @param D Data matrix of dimensions 100-by-N, where N is the number of observations
##' @param k Number of coins
##' @param lambda Vector of mixture weights
##' @param theta Vector of probabilities of obtaining heads
##' @param tolerance A threshold used to check convergence
coin_EM <- function(D, k, lambda, theta, tolerance = 1e-2) {
# expected complete-data (hidden) log-likelihood
ll_hid <- -Inf
# observed log-likelihood
ll_obs <- -Inf
# difference between two iterations
diff <- Inf
# number of observations
N <- nrow(D)
# responsibilities
gamma <- matrix(0, nrow = k, ncol = N)
# run the E-step and M-step until convergence
while (diff > tolerance) {
# store old likelihood
ll_obs_old <- ll_obs
############# E-step #############
### YOUR CODE STARTS ###
# Compute the responsibilities
# Define the probability of data given theta
prob_x_theta <- rbind(theta[1] ** (rowSums(D == 1)) + (1 - theta[1]) ** (rowSums(D==0)),
theta[2] ** (rowSums(D == 1)) + (1 - theta[2]) ** (rowSums(D==0)))
# Find the respective responsibility vector
lambda_prob_prod <- data.table(rbind(lambda[1] * prob_x_theta[1,], lambda[2] * prob_x_theta[2,]))
gamma <- lambda_prob_prod[, lapply(.SD, function(x) x/sum(x))]
# Update expected complete-data (hidden) log-likelihood
# For binary cases the log likelihood is also following the same
ll_hid <- sum(gamma * log(lambda_prob_prod))
# Update observed log-likelihood
ll_obs <- ll_hid
# Recompute difference between two iterations
diff <- ll_obs - ll_obs_old
### YOUR CODE ENDS ###
############# M-step #############
### YOUR CODE STARTS ###
# Recompute priors (mixture weights)
lambda <- rowMeans(gamma)
# Recompute probability of heads for each coin
theta <- c(sum(gamma[1,] * rowSums(D == 1))/(100*sum(gamma[1,])),
sum(gamma[2,] * rowSums(D == 1))/(100*sum(gamma[2,])))
### YOUR CODE ENDS ###
}
return(list(ll_hid = ll_hid, ll_obs = ll_obs, lambda = lambda, theta = theta, gamma = gamma))
}
res <- coin_EM(D, k, lambda, theta)
## YOUR CODE ##
cat(sprintf(
"The probability of heads are:
coin 1: %.3f
coin 2: %.3f",
res$theta[1], res$theta[2]))
## YOUR CODE ##
cat(sprintf(
"The mixture weights are:
coin 1 : %.3f
coin 2 : %.3f ",
res$lambda[1], res$lambda[2]
))
## YOUR CODE ##
pheatmap::pheatmap(res$gamma, color = viridis_pal(option = "D")(100))
## YOUR CODE ##
cat("The number of observation for each coin is predicted below: \n")
knitr::kable(table(as.numeric(gamma[, lapply(.SD, which.max)])))
## YOUR CODE ##
pheatmap::pheatmap(res$gamma, color = viridis_pal(option = "D")(100))
## YOUR CODE ##
cat("The number of observation for each coin is predicted below: \n")
(table(as.numeric(gamma[, lapply(.SD, which.max)])))
is.data.table(gamma)
gamma
(table(as.numeric(res$gamma[, lapply(.SD, which.max)])))
## YOUR CODE ##
cat("The number of observation for each coin is predicted below: \n")
(table(as.numeric(res$gamma[, lapply(.SD, which.max)])))
## YOUR CODE ##
cat("The number of observation for each coin is predicted below: \n")
knitr::kable(table(as.numeric(res$gamma[, lapply(.SD, which.max)])))
?prod
## YOUR CODE ##
pheatmap::pheatmap(res$gamma, color = viridis_pal(option = "D")(100))
setwd("~/Desktop/EthZ/Courses/Sem_4/Statistical_Model_CB/Exercise/Project_2")
